<?xml version="1.0" encoding="UTF-8"?>
  <rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
      <title></title>
      <description></description>
      <link>https://simply-jekyll.netlify.app///</link>
    <atom:link href="https://simply-jekyll.netlify.app///feed.xml" rel="self" type="application/rss+xml"/>
      <pubDate>Thu, 11 Aug 2022 17:13:50 -0500</pubDate>
      <lastBuildDate>Thu, 11 Aug 2022 17:13:50 -0500</lastBuildDate>
      <generator>Jekyll v4.0.1</generator>
      <item>
        <title>SOP Key points, and Drafts</title>
        <description>&lt;h2 id=&quot;board1&quot;&gt;board1&lt;/h2&gt;
          &lt;ul class=&quot;task-list&quot;&gt;
          &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;Slides.com transfer&lt;/li&gt;
          &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;Fix/patch base&lt;/li&gt;
          &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;Setup t5se&lt;/li&gt;
          &lt;/ul&gt;
          &lt;h2 id=&quot;board2&quot;&gt;board2&lt;/h2&gt;
          &lt;ul class=&quot;task-list&quot;&gt;
          &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;temp&lt;/li&gt;
          &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;temp&lt;/li&gt;
          &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;temp&lt;/li&gt;
          &lt;/ul&gt;
          &lt;p&gt;%% kanban:settings&lt;/p&gt;
          &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;0
          &lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;{&quot;kanban-plugin&quot;:&quot;basic&quot;}
          &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
          &lt;p&gt;%%&lt;/p&gt;
        </description>
        <pubDate>Wed, 10 Aug 2022 00:00:00 -0500</pubDate>
        <link>https://simply-jekyll.netlify.app///thoughts/SOP</link>
      <guid isPermaLink="true">https://simply-jekyll.netlify.app///thoughts/SOP</guid>
    </item>
    <item>
      <title>Points to study</title>
      <description>&lt;ul&gt;
        &lt;li&gt;Machine Learning
        &lt;ul&gt;
        &lt;li&gt;Lecture 1
        &lt;ul&gt;
        &lt;li&gt;Hypothesis Testing&lt;/li&gt;
        &lt;li&gt;Density Estimation&lt;/li&gt;
        &lt;li&gt;Multi Instance Learning&lt;/li&gt;
        &lt;/ul&gt;
        &lt;/li&gt;
        &lt;/ul&gt;
        &lt;/li&gt;
        &lt;/ul&gt;
      </description>
      <pubDate>Sun, 09 Jan 2022 00:00:00 -0600</pubDate>
      <link>https://simply-jekyll.netlify.app///notes/basics_of_probability</link>
    <guid isPermaLink="true">https://simply-jekyll.netlify.app///notes/basics_of_probability</guid>
  </item>
  <item>
    <title>Basics of Probability</title>
    <description>&lt;h1 id=&quot;probability&quot;&gt;Probability&lt;/h1&gt;
      &lt;p&gt;Measure of a subset under relation pretex&lt;/p&gt;
      &lt;h2 id=&quot;basic-terms&quot;&gt;Basic Terms&lt;/h2&gt;
      &lt;ul&gt;
      &lt;li&gt;Sample Space, Event, Proper Subset, Disjoint, Event Space,&lt;/li&gt;
      &lt;li&gt;Event space for a countable sample space is $2^k$ where k is the distince outcomes&lt;/li&gt;
      &lt;li&gt;Parition of Set: Disjoint, Union is that Set&lt;/li&gt;
      &lt;li&gt;Decomposing a set into disjoint if we have a parition available,&lt;/li&gt;
      &lt;li&gt;Sample Space is all possible outcomes, while Event Space includes the outcomes which we are interested about&lt;/li&gt;
      &lt;li&gt;Field (Formal gurrantee of Event Space, Sigma and Borel Sigma field on infinite sets)&lt;/li&gt;
      &lt;li&gt;Measure Zero Set, it is non zero if the sample space is countable or the event is not an isolated point wrt to sample space.
      &lt;ul&gt;
      &lt;li&gt;or in other words for continuous distribution its area under the curve and otherwise its countable&lt;/li&gt;
      &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Axioms- Additive, Normalized and Non-Negative&lt;/li&gt;
      &lt;li&gt;Conditional Probability of $P(A|B)$ will not be defined if $P(B) = 0$ as then the sample space of new event wont be valid.&lt;/li&gt;
      &lt;li&gt;Independent Events: $P(A|B) = P(A)$&lt;/li&gt;
      &lt;li&gt;Disjoint is $P(A\cap B) = \phi$, while Independence is $P(A\cap B) = P(A)P(B)$
      &lt;ul&gt;
      &lt;li&gt;Conceptually Disjoint is Getting a head and Getting a tail, while Independent is Getting 6 on dice and Getting a tail, and dependent is Getting a sum of more than 8 when two dice are rolled.&lt;/li&gt;
      &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Bayes - $P[A|B]P[B] = P[B|A]P[A]$
      &lt;ul&gt;
      &lt;li&gt;If $P[A|B]$ is conditional (or likelihood) than $P[B|A]$ is posterior, $P[B]$ is prior.&lt;/li&gt;
      &lt;/ul&gt;
      &lt;/li&gt;
      &lt;/ul&gt;
      &lt;h2 id=&quot;random-variables&quot;&gt;Random Variables&lt;/h2&gt;
      &lt;ul&gt;
      &lt;li&gt;Random Variable maps events in probability to real valued data (numbers)&lt;/li&gt;
      &lt;li&gt;Probability Mass function represents the probability of all the states of that data (histogram)
      &lt;ul&gt;
      &lt;li&gt;Probability density function is the counter part of PMF for continuous variables&lt;/li&gt;
      &lt;li&gt;PMF = PFD*Delta functions&lt;/li&gt;
      &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Expectation (or Mean) is the average value of the PMF&lt;/li&gt;
      &lt;li&gt;Histogram number of bins, can be $\sqrt{N}, \log_2 N+1$&lt;/li&gt;
      &lt;li&gt;Cumulative Distribution function for any given point X, is the area under the graph for $x \in [-\inf, X]$
      &lt;ul&gt;
      &lt;li&gt;Increasing function, minimum is 0 and maximum is 1&lt;/li&gt;
      &lt;li&gt;CDF is always right continuous i.e. f(x) == f(x+h)&lt;/li&gt;
      &lt;li&gt;because probability of event f(3+h) needs to include f(3)&lt;/li&gt;
      &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Expectation of a random variable need not to be translated back to the actual events
      &lt;ul&gt;
      &lt;li&gt;If we have a coin with $P(H) = \frac{3}{4}$ and $P(T) = \frac{1}{4}$,&lt;/li&gt;
      &lt;li&gt;We denote these events with random variables X(H) = 0, X(T) = 1&lt;/li&gt;
      &lt;li&gt;then E[X] = $0*\frac{3}{4} + 1\frac{1}{4} = \frac{1}{4}$&lt;/li&gt;
      &lt;li&gt;$E[g(x)] = \sum_{x\in \Omega} g(x) PMF(x)$; Expectation of any function is scaling the x axis with the function values but the PMF stays the same as it is the frequency with which those events occur&lt;/li&gt;
      &lt;li&gt;so the expectation denotes the average value on the number line scale defined by random variable not on the events as such; and expectation is equivalent to finding the center of mass.&lt;/li&gt;
      &lt;li&gt;kth Moment is $E[x^k]$; Variance = $E[(x-\mu)^2]$&lt;/li&gt;
      &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;PMF exists for which the mean is less than infinite, and those PMF does not have any valid Mean&lt;/li&gt;
      &lt;li&gt;Cauchy Random variable - PDF with infinite mean&lt;/li&gt;
      &lt;li&gt;kth Moment of PDF
      &lt;ul&gt;
      &lt;li&gt;$\int x^k f_X(x) dx$&lt;/li&gt;
      &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Variance = $E(X^2) - {\mu}^2$&lt;/li&gt;
      &lt;li&gt;Median = point when the sum of PDF on the left hand side is same as right hand side.&lt;/li&gt;
      &lt;li&gt;Mode = point with highest PDF or steepest CDF slope&lt;/li&gt;
      &lt;li&gt;Mean = Integration of 1-CDF, it can be proven by rearranging&lt;/li&gt;
      &lt;/ul&gt;
      \[\begin{aligned}
      \mu &amp;amp;= \int_0^\infty 1-F(x) dx\\
      &amp;amp;= \int_0^\infty {1-F(x)} dx\\
      &amp;amp;= \int_0^\infty {1-\int_0^y f(y) dy} dx\\
      &amp;amp;= \int_0^\infty {\int_y^\infty f(y) dy} dx\\
      &amp;amp;= \int_0^\infty \int_0^y f(y) dx dy\\
      &amp;amp;= \int_0^\infty  yf(y) dy\\
      \end{aligned}\]
      &lt;p&gt;The above derivation is possible because of change in the order of &lt;a href=&quot;https://ocw.mit.edu/courses/mathematics/18-02sc-multivariable-calculus-fall-2010/3.-double-integrals-and-line-integrals-in-the-plane/part-a-double-integrals/session-49-exchanging-the-order-of-integration/MIT18_02SC_we_20_comb.pdf&quot;&gt;integration&lt;/a&gt; i.e. changing the flow in which we cover the area&lt;/p&gt;
      &lt;p&gt;##Distributions&lt;/p&gt;
      &lt;ul&gt;
      &lt;li&gt;Bernoulli Distribution
      &lt;ul&gt;
      &lt;li&gt;Two events with probability $p\delta (X-1)*1-p\delta(X)$&lt;/li&gt;
      &lt;li&gt;Variance of p(1-p) and mean of p; has maximum variance if p = 1/2 or unbiased.&lt;/li&gt;
      &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Binomial Distribution
      &lt;ul&gt;
      &lt;li&gt;Probability: $C^n_r p^n (1-p)^{n-r}$&lt;/li&gt;
      &lt;li&gt;Variance is np(1-p) and mean is np; has maximum variance with p = 1/2 and as number of events increases&lt;/li&gt;
      &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Geometric Distribution
      &lt;ul&gt;
      &lt;li&gt;Probability: $(1-p)^{k-1}p$&lt;/li&gt;
      &lt;li&gt;Mean is $\frac{1}{p}$&lt;/li&gt;
      &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Poisson Distribution
      &lt;ul&gt;
      &lt;li&gt;Aims to model the occurance of events, like arrival of telephone, calling an uber&lt;/li&gt;
      &lt;li&gt;Probability: $p_x(k) = \frac{\lambda^k}{k!}e^{-\lambda}$ for one time interval and $\lambda$ becomes $t\lambda$ if we are looking for probability of event in t intervals.&lt;/li&gt;
      &lt;li&gt;It is directly linked to the value of $\lambda$ which is also known as poisson rate.&lt;/li&gt;
      &lt;li&gt;Probaility is directly proportional to the rate of event and to the probability with which that event would take place&lt;/li&gt;
      &lt;li&gt;Poisson Distribution is government by different properties
      &lt;ul&gt;
      &lt;li&gt;Probability of event should be independent of each other&lt;/li&gt;
      &lt;li&gt;and because of the same it is not possible to get only one event in a given interval&lt;/li&gt;
      &lt;li&gt;as if the Probability of occurence in an event wrt to previous event would have to be 0 which would make it dependent.
      -i&lt;/li&gt;
      &lt;/ul&gt;
      &lt;/li&gt;
      &lt;/ul&gt;
      &lt;/li&gt;
      &lt;/ul&gt;
      &lt;h2 id=&quot;machine-learning&quot;&gt;Machine Learning&lt;/h2&gt;
      &lt;ul&gt;
      &lt;li&gt;Semi Supervised Learning
      &lt;ul&gt;
      &lt;li&gt;Multi Instance learning&lt;/li&gt;
      &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;UnSupervised Learning&lt;/li&gt;
      &lt;/ul&gt;
      &lt;h1 id=&quot;phylogeny&quot;&gt;Phylogeny&lt;/h1&gt;
      &lt;p&gt;Given a VAFs, the task is to generate ancestoral tree such that it adheres to the principles of perfect phylogeny.&lt;/p&gt;
      &lt;h2 id=&quot;terminology&quot;&gt;Terminology&lt;/h2&gt;
      &lt;ul&gt;
      &lt;li&gt;M matrix of size $(m, n)$ denotes the presence of $m^{th}$ mutation in $n^{th}$ location of the tumor.&lt;/li&gt;
      &lt;li&gt;V matrix of size $(m, n)$ represents VAFs of $m^{th}$ sample in $n^{th}$ location of the tumor.&lt;/li&gt;
      &lt;li&gt;T tree, provides the ancestoral representation of mutations based on phylogeny of M matrix.&lt;/li&gt;
      &lt;li&gt;Character, represents the language of mutation and in our case T or A denoting whether Tumor has been found at a particular site or not.&lt;/li&gt;
      &lt;/ul&gt;
      &lt;h2 id=&quot;perfect-phylogeny&quot;&gt;Perfect Phylogeny&lt;/h2&gt;
      &lt;blockquote&gt;
      &lt;p&gt;A phylogeny tree is perfect if it follows the following principle,&lt;/p&gt;
      &lt;/blockquote&gt;
      &lt;ul&gt;
      &lt;li&gt;Mathematically, there should be no conflict between the mutations at any two sites.&lt;/li&gt;
      &lt;/ul&gt;
      \[Conflict (i, j) = 
      \begin{cases}
      true, &amp;amp; \text{} M[k, j] \nleqslant M[k, i], M[k, j] \ngeqslant M[k, i], \forall k \in m.  \\
      &amp;amp;\text{} M[k, j] = M[k, i], \exists k \in m.  \\
      false, &amp;amp; otherwise
      \end{cases}\]
      &lt;p&gt;$\quad$ for example,&lt;/p&gt;
      \[M = \begin{bmatrix}
      1&amp;amp;0&amp;amp;0&amp;amp;0\\
      1&amp;amp;1&amp;amp;1&amp;amp;0\\
      0&amp;amp;0&amp;amp;0&amp;amp;1\\
      0&amp;amp;1&amp;amp;0&amp;amp;0
      \end{bmatrix}\]
      &lt;p&gt;$\quad$ Column 1 and 2 in Matrix, M are in conflict while column 3 and 4 are not.&lt;/p&gt;
      &lt;ul&gt;
      &lt;li&gt;
      &lt;p&gt;Intutively, it is because we can say that that column 3 is ancestoral clone of column 2 but we cant say the same for column 1 and 2. While with column 3 and 4, we can say these are not ancestoral clones.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
      &lt;p&gt;Perfect Phylogeny, also ensures the invention of new character&lt;a class=&quot;citation&quot; href=&quot;#vingron2003algorithms&quot;&gt;[1]&lt;/a&gt; is a rare events and does not happen in multiple sites across the phylogeny tree.&lt;/p&gt;
      &lt;/li&gt;
      &lt;/ul&gt;
      &lt;h3 id=&quot;generation-of-evolutionary-tree-from-perfect-phylogeny&quot;&gt;Generation of Evolutionary tree from Perfect Phylogeny&lt;/h3&gt;
      &lt;p&gt;Given M, which has no conflict present in the columns, finding ancestors required as to&lt;/p&gt;
      &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;0
      1
      2
      3
      4
      5
      6
      7
      8
      9
      10
      11
      12
      13
      14
      15
      16
      &lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;Input : M
      function(map)
      function(M):
      sort(M) over columns.
      append($C_0$, M), where $C_0 \in \{0\}.$ 
      for $C, C&apos;$ in columns, where $C&apos; \ne C$:
      if $C&apos; \subseteq C$ then
      draw an edge in T from $C \to C&apos;$;
      for each_node in T:
      get(characters required)
      check : any row uses these characters
      if yes:
      label node as that row.
      &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;p&gt;Example:&lt;/p&gt;
      \[M = \begin{bmatrix}
      0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1\\
      0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0\\
      0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;1&amp;amp;0\\
      0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0\\
      0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\
      0&amp;amp;1&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\
      1&amp;amp;1&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0
      \end{bmatrix},
      M_{sorted} = 
      \begin{bmatrix}
      1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1\\
      1&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\
      1&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0\\
      1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0\\
      1&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\
      1&amp;amp;1&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\
      1&amp;amp;1&amp;amp;1&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0
      \end{bmatrix}\]
      &lt;table&gt;
      &lt;thead&gt;
      &lt;tr&gt;
      &lt;th&gt;&lt;img src=&quot;../assets/imgs/phylogeny_m_inpt.png&quot; alt=&quot;&quot; /&gt;&lt;/th&gt;
      &lt;th&gt;&lt;img src=&quot;../assets/imgs/columns_decomposition.png&quot; alt=&quot;&quot; /&gt;&lt;/th&gt;
      &lt;/tr&gt;
      &lt;/thead&gt;
      &lt;tbody&gt;
      &lt;tr&gt;
      &lt;td&gt;Tree with nodes representing columns&lt;/td&gt;
      &lt;td&gt;Tree with nodes representing mutation, and Yellow color nodes representing derived mutation&lt;/td&gt;
      &lt;/tr&gt;
      &lt;/tbody&gt;
      &lt;/table&gt;
      &lt;h2 id=&quot;importance-of-vafs-in-phylogeny&quot;&gt;Importance of VAFs in phylogeny&lt;/h2&gt;
      &lt;table&gt;
      &lt;thead&gt;
      &lt;tr&gt;
      &lt;th&gt;&lt;img src=&quot;../assets/imgs/phylogeny_vaf_inpt.png&quot; alt=&quot;&quot; /&gt;&lt;/th&gt;
      &lt;th&gt;&lt;img src=&quot;../assets/imgs/vaf_columns_decomposition.png&quot; alt=&quot;&quot; /&gt;&lt;/th&gt;
      &lt;/tr&gt;
      &lt;/thead&gt;
      &lt;tbody&gt;
      &lt;tr&gt;
      &lt;td&gt;Tree with nodes representing columns&lt;/td&gt;
      &lt;td&gt;Tree with nodes representing mutation, and Yellow color nodes representing derived mutation&lt;/td&gt;
      &lt;/tr&gt;
      &lt;/tbody&gt;
      &lt;/table&gt;
      &lt;p&gt;When we added VAFs information to the mutations, we were able to infer inner relationship between the nodes which got lost with binary representation of M matrix.&lt;/p&gt;
      &lt;h2 id=&quot;maximum-parsimony&quot;&gt;Maximum Parsimony&lt;/h2&gt;
      &lt;ul&gt;
      &lt;li&gt;In real world experiments, we are not gurranteed to get perfect phylogeny from the sequencing, and that’s where the principle of maximum parsimony plays its role.&lt;/li&gt;
      &lt;li&gt;Our aim is to generate parsimonious tree from the input data, i.e. a tree which can represent the M matrix in the best possible representation.&lt;/li&gt;
      &lt;li&gt;Algorithm (It uses distance based clustering for generation of tree, and Fitcher’s small parsimony principle for labeling of derived clones)
      &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;0
      1
      2
      3
      &lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;      &lt;span class=&quot;nc&quot;&gt;Create&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;separate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cluster&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
      &lt;span class=&quot;nf&quot;&gt;Iteratively&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;till&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;we&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;have&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;only&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;one&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cluster&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;Given&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;all&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clusters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;merge&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;two&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clusters&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;which&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;has&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minimum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
      &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
      &lt;p&gt;where&lt;/p&gt;
      \[distance(a, b) = \frac{distance(a) + distance(b)}{2},\]
      &lt;p&gt;and initial distance between two clones are calculated as the edit distance between two clones.&lt;/p&gt;
      &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;0
      1
      2
      3
      4
      5
      6
      7
      8
      9
      10
      11
      12
      13
      14
      &lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;      Given : Tree
      At first,
      In bottom up fashion, for each location(k) of node i,$$
      Cn_i^k = \begin{cases}
      \cup(Cn_j^k) &amp;amp; if \cap(Cn_j^k) = \phi, where\ n_j = child(n_i)\\
      \cap(Cn_j^k) &amp;amp; otherwise\\
      \end{cases}
      $$
      In the top down fashion, for each location(k) of node i,$$
      Cn_i^k = \begin{cases}
      Cn_i^k = Cn_j^k &amp;amp; if Cn_j^k \in Cn_i^k, where\ n_j^k = parent(n_i^k)\\
      Cn_i^k = random(Cn_i^k, 1) &amp;amp; otherwise
      \end{cases}
      $$
      &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
      &lt;/li&gt;
      &lt;/ul&gt;
      &lt;h2 id=&quot;mixphy&quot;&gt;MixPhy&lt;/h2&gt;
      &lt;ul&gt;
      &lt;li&gt;With Fletcher’s Algorithm and Agglomerative clustering, we aimed to find the best parsimonious tree from the M but it does not takes into the account key factors that clones in M might have been mixed.&lt;/li&gt;
      &lt;li&gt;That’s where the problem of Maximum parsimony comes into account. The problem states that we have to find the best steiner tree from the input M.&lt;/li&gt;
      &lt;li&gt;MixPhy solved this Np-hard problem heuristically by restructing the input as a perfect graph and coloring rows which will get split into multiple clones.&lt;/li&gt;
      &lt;li&gt;Algorithm
      &lt;ul&gt;
      &lt;li&gt;For the given M, create a graph, G in which two columns are connected if either one is contained in another.
      where, contained is defined as if all of the element are either $\leq$ or $\geq$.&lt;/li&gt;
      &lt;li&gt;As the containment is a transitive in nature,&lt;/li&gt;
      &lt;li&gt;i.e. if {0, 0, 1} is contained in {0, 1, 1} and {0, 1, 1} is contained in {1, 1, 1} then {0, 0, 1} is also contained in {1, 1, 1}&lt;/li&gt;
      &lt;li&gt;Thus the output graphs becomes perfect in nature, and the problem of finding cliques becomes polynomially complex.&lt;/li&gt;
      &lt;li&gt;If we observe the complement of G is the conflict graph in which any two columns are connected if both are conflicting in nature.&lt;/li&gt;
      &lt;li&gt;Thus coloring a clique of graph G, with the same color will lead to no two adjacent columns having the same color in the conflict graph.&lt;/li&gt;
      &lt;li&gt;and for each row in M:
      if color of all of the mutated column is same, then we do not need to split it
      otherwise it will get splitted into k different rows where k are the number of unique colors required to color that row.&lt;/li&gt;
      &lt;/ul&gt;
      &lt;/li&gt;
      &lt;/ul&gt;
    </description>
    <pubDate>Sun, 09 Jan 2022 00:00:00 -0600</pubDate>
    <link>https://simply-jekyll.netlify.app///notes/basics_of_probability</link>
  <guid isPermaLink="true">https://simply-jekyll.netlify.app///notes/basics_of_probability</guid>
</item>
<item>
  <title>Phylogeny of tumor Cells</title>
  <description>&lt;p&gt;Phylogeny is the study of organisms, but it has gained quite an attraction in cancer study because of tumor cells being heterogeneous, which implies that the morphological behavior of two cells differs, but their genetic structure changes.&lt;/p&gt;
  </description>
  <pubDate>Thu, 25 Mar 2021 00:00:00 -0500</pubDate>
  <link>https://simply-jekyll.netlify.app///project/CSE690</link>
<guid isPermaLink="true">https://simply-jekyll.netlify.app///project/CSE690</guid>
</item>
<item>
  <title>Deep Learning</title>
  <description>&lt;p&gt;In this work, we investigate the problem of colorization of grayscale images. This problem is ill-defined and underconstrained which is why earlier works in this domain have relied on heavy user interaction. We first explored Deep Colorization, which uses multi- scale features and deep neural networks for colorization.&lt;/p&gt;
  </description>
  <pubDate>Thu, 25 Mar 2021 00:00:00 -0500</pubDate>
  <link>https://simply-jekyll.netlify.app///project/CSE641</link>
<guid isPermaLink="true">https://simply-jekyll.netlify.app///project/CSE641</guid>
</item>
<item>
  <title>Introduction to Quantum Computing</title>
  <description>&lt;p&gt;The problem of decomposing a N ×N unitary into a quantum circuit was inspired from Task- 4 of IBM Quantum Challenge, 2020. In that challenge, we were asked to design a quantum circuit for a predefined unitary matrix, such that it requires a minimum number of gates. One of the approaches with which this problem can be tackled is to use a machine learning algorithm, in which parameters of U3 gates are learned using gradient descent algorithm with the norm between U and circuit used as the cost function. In this project, at first analytical methods to compute the gradients were used, which worked well for classification related tasks but could not hold up to unitary estimation. After that, numerical gradient estimation techniques were used to solve the problem.&lt;/p&gt;
  </description>
  <pubDate>Thu, 25 Mar 2021 00:00:00 -0500</pubDate>
  <link>https://simply-jekyll.netlify.app///project/CSE622</link>
<guid isPermaLink="true">https://simply-jekyll.netlify.app///project/CSE622</guid>
</item>
<item>
  <title>Natural Language Processing</title>
  <description>&lt;p&gt;Concept of context Understanding in Natural Language Processing (NLP) has led to paradigm shift from word embedding based models to inculcation of semantics and context based features.It has great applications when it comes to machine language generation,dialog mod- eling ,etc for improving the quality and relevance.&lt;/p&gt;
  </description>
  <pubDate>Thu, 25 Mar 2021 00:00:00 -0500</pubDate>
  <link>https://simply-jekyll.netlify.app///project/CSE556</link>
<guid isPermaLink="true">https://simply-jekyll.netlify.app///project/CSE556</guid>
</item>
<item>
  <title>Advance Computer Vision</title>
  <description>&lt;p&gt;This project extends the barebone conditional autoregressive network towards faster training, evalua- tion, and learning to color from thermal input instead of grayscale.&lt;/p&gt;
  </description>
  <pubDate>Thu, 25 Mar 2021 00:00:00 -0500</pubDate>
  <link>https://simply-jekyll.netlify.app///project/CSE544</link>
<guid isPermaLink="true">https://simply-jekyll.netlify.app///project/CSE544</guid>
</item>
<item>
  <title>Colorization - Sampling Color from GrayScale and I.R. Images</title>
  <description>&lt;p&gt;Given a grayscale image, it is a daunting task, even for a human, to visualize it in color. See Figure 1 for examples. However, a human may try to find semantic clues like texture and world knowledge to assign colors to objects. For example, the grass is mostly green, or the sky is mostly blue. But these clues may also fail sometimes, as shown in Figure 1(middle). Thus, in this work, the focus was on assigning a plausible set of colors to the Image, which may or may not be the same as the ground truth.&lt;/p&gt;
    &lt;p&gt;&lt;img src=&quot;../assets/imgs/2021-01-21-15-43-47.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
    &lt;p&gt;&lt;em&gt;Fig:1 GrayScale Images and Corresponding Color&lt;/em&gt;&lt;/p&gt;
    &lt;blockquote&gt;
    &lt;p&gt;The primary motivation behind pursuing this problem was that many images do not have color information. Also, the problem of Colorization is self-supervised and does not require a pair-wise dataset.&lt;/p&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;The aim is to solve it in generative fashion, such that if we feed the same grayscale Image to the network k times, it may generate different output each time. A generative network’s benefit is that it may color the cloth’s stripes (Figure 2), gray or red.&lt;/p&gt;
    &lt;p&gt;&lt;img src=&quot;../assets/imgs/2021-01-22-11-34-00.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
    &lt;p&gt;&lt;em&gt;Fig:2 Plants in the left Image are entirely green, not in the right&lt;/em&gt;&lt;/p&gt;
    &lt;p&gt;The solution is based on PixColor, which is state of the art autoregressive generative neural networks for Colorization, i.e., the output of $i^{th}$ pixel is not just conditioned on the latent representation of the grayscale Image, X but also on the previous outputs, $[i-t, i-t+1, i-t+2\ …\ i-1]$ where t denotes the receptive field.&lt;/p&gt;
    &lt;p&gt;Given $X \in [H, W]$, we first extracts the features $Y_1$ using Resnet-101 of size $[\frac{H}{4}, \frac{W}{4}, 1024]$. These features are then passed into an adaption network and use three convolution layers to adapt the features required by pixelcnn. The output from the adaption network is of size $[\frac{H}{4}, \frac{W}{4}, 64]$, and is fed into conditional pixelcnn. It masks the weights of a convolutional layer to prohibit pixel $x_i$ from using any information about the future samples $(x_{i+1:N})$.&lt;/p&gt;
    &lt;p&gt;Training is the same as that of any other end-to-end trainable architecture (as ground truth data was used under teacher training mechanism), but during testing, for each pixel $i$, the class is sampled from a multinomial distribution defined by the softmax output of the network.&lt;/p&gt;
    &lt;p&gt;&lt;img src=&quot;../assets/imgs/2021-01-22-15-36-30.png&quot; alt=&quot;&quot; /&gt;
    &lt;em&gt;Fig:3 Result of Colorization Algorithm&lt;/em&gt;&lt;/p&gt;
    &lt;p&gt;The first seven images in carousal(at the top) are the PixColor algorithm results with key insights from each of the Images.&lt;/p&gt;
    &lt;h2 id=&quot;extension-towards-ir-images&quot;&gt;Extension towards I.R. images&lt;/h2&gt;
    &lt;p&gt;I decided to continue working on image colorization during my next semester, focusing on ​reducing the artifacts and ​improving larger objects’ coloring​. The output from pixelcnn is given to a fully convolutional network, acting as a denoiser, inspired by Tacotron, a source synthesis architecture.
    &lt;img src=&quot;../assets/imgs/2021-01-22-15-16-49.png&quot; alt=&quot;&quot; /&gt;
    &lt;em&gt;Fig:4 Correction of Green Artifact as shown in left Image&lt;/em&gt;&lt;/p&gt;
    &lt;p&gt;After that, my professor suggested applying image colorization on I.R. images. In applications under low lighting, I.R. cameras come in handy, but interpreting I.R. images is not straightforward for a human, and hence translating to RGB improves its understandability. I.R. images introduced two challenges, i) it is no longer a self-supervised task and requires a parallel dataset, ii) it is computationally expensive since with grayscale images, we can learn the color information at less spatial resolution(Figure 5-middle) and upscale it, with minimal impact on visual quality but with I.R. images, we need to learn Luminicance too(Figure 5-bottom).&lt;/p&gt;
    &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;Input Image&lt;/th&gt;
    &lt;th&gt;&lt;img src=&quot;../assets/imgs/2021-01-22-15-22-11.png&quot; alt=&quot;&quot; /&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
    &lt;td&gt;Color channels&lt;br /&gt; downscaled and&lt;br /&gt; Interploated&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-22-15-22-58.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;All channels are&lt;br /&gt; downscaled and&lt;br /&gt; interpolated&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-22-15-23-21.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
    &lt;/table&gt;
    &lt;p&gt;&lt;em&gt;Figure 5: Effect of downsampling on image quality&lt;/em&gt;&lt;/p&gt;
    &lt;p&gt;For I.R. to RGB, I did not directly use PixelColor to generate color images but first used ImageGAN with wassterin loss. It ended up being blurry because we were averaging the loss over all of the pixels (Table - 1).&lt;/p&gt;
    &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;Input - IR&lt;/th&gt;
    &lt;th&gt;Target - RGB&lt;/th&gt;
    &lt;th&gt;Output - RGB&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-22-15-41-01.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-22-15-41-24.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-22-15-41-32.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-22-15-42-40.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-22-15-42-49.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-22-15-42-57.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
    &lt;/table&gt;
    &lt;p&gt;&lt;em&gt;Table:1 Blurry Output when GAN’s are not used&lt;/em&gt;&lt;/p&gt;
    &lt;p&gt;An I.R. image is first passed through GAN, which generates grayscale output followed by PixColor for sampling RGB from the generated grayscale.&lt;/p&gt;
    &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;Input I.R.&lt;/th&gt;
    &lt;th&gt;Target GrayScale&lt;/th&gt;
    &lt;th&gt;Generated GrayScale&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-24-19-26-49.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-24-19-27-04.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-24-19-27-15.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-24-19-28-14.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-24-19-28-30.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-24-19-28-46.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-24-19-29-55.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-24-19-30-02.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-24-19-30-08.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-24-19-44-27.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-24-19-44-42.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-24-19-44-49.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-24-19-45-59.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-24-19-46-12.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-24-19-46-25.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-24-19-48-05.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-24-19-48-17.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/2021-01-24-19-48-30.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
    &lt;/table&gt;
    &lt;p&gt;&lt;em&gt;Table 2: Output of ImageGAN&lt;/em&gt;&lt;/p&gt;
    &lt;p&gt;The ImageGAN model produced close to ground truth for many situations (Table 2 first four rows). Still, the model’s performance deteriorated when uncommon objects were present in the I.R. image, like a person on the cycle or person themselves, highlighting the importance of richer data sources.&lt;/p&gt;
    &lt;p&gt;The last five images in carousal(at the top) are the results of the I.R. to color algorithm with key insights from each of the Images.&lt;/p&gt;
    &lt;h2 id=&quot;datasets&quot;&gt;Datasets&lt;/h2&gt;
    &lt;p&gt;The ADE20K  scene parsing dataset was used for PixColor training; it has 20K training and 1.5k validation samples. Also, there was a pretrained resnet101 network, which helped speed up the training process.
    For I.R. to RGB translation, the kaist multispectral benchmark was used. It is divided into multiple files, with each file consisting of over 10000 images, but it lacks the spatial resolution. I tested six different datasets that have pair-wise I.R. and RGB images and found it to be most aligned.&lt;/p&gt;
    &lt;h2 id=&quot;training-and-analysis&quot;&gt;Training and Analysis&lt;/h2&gt;
    &lt;p&gt;PixColor was trained for 50 epochs, in 100% teacher-training mechanism, i.e. during training pixelcnn autoregressive considers ground truth samples as previous t inputs. The ImageGAN was trained for 150 epochs, I stopped after 150 epochs due to computation constraints. Evaluating generative models is very hard, that’s why I tested the color distribution generated by the PixColor and observed biases towards the brown color which was present in the ADE20k data itself.&lt;/p&gt;
    &lt;p&gt;&lt;img src=&quot;../assets/imgs/2021-01-24-21-53-44.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
    &lt;p&gt;Currently, I am studying more about GANs to train them effectively with fewer data points, if you have any questions or suggestion, please let me know on &lt;a href=&quot;https://twitter.com/itskdme&quot;&gt;Twitter&lt;/a&gt; or &lt;a href=&quot;https://www.instagram.com/itskd.me/&quot;&gt;instagram&lt;/a&gt;.&lt;/p&gt;
    &lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
    &lt;ul&gt;
    &lt;li&gt;Guadarrama, Sergio, et al. “Pixcolor: Pixel recursive colorization.” arXiv preprint arXiv:1705.07208 (2017).&lt;/li&gt;
    &lt;li&gt;Salimans, Tim, et al. “Pixelcnn++: Improving the pixelcnn with discretized logistic mixture likelihood and other modifications.” arXiv preprint arXiv:1701.05517 (2017).&lt;/li&gt;
    &lt;li&gt;Oord, Aaron van den, et al. “Conditional image generation with pixelcnn decoders.” arXiv preprint arXiv:1606.05328 (2016).&lt;/li&gt;
    &lt;li&gt;Zhou, Bolei, et al. “Scene parsing through ade20k dataset.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.&lt;/li&gt;
    &lt;li&gt;Hwang, Soonmin, et al. “Multispectral pedestrian detection: Benchmark dataset and baseline.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2015.&lt;/li&gt;
    &lt;li&gt;Wang, Yuxuan, et al. “Tacotron: Towards end-to-end speech synthesis.” arXiv preprint arXiv:1703.10135 (2017).&lt;/li&gt;
    &lt;li&gt;Arjovsky, Martin, Soumith Chintala, and Léon Bottou. “Wasserstein generative adversarial networks.” International conference on machine learning. PMLR, 2017.&lt;/li&gt;
    &lt;li&gt;Isola, Phillip, et al. “Image-to-image translation with conditional adversarial networks.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.&lt;/li&gt;
    &lt;/ul&gt;
  </description>
  <pubDate>Thu, 14 Jan 2021 00:00:00 -0600</pubDate>
  <link>https://simply-jekyll.netlify.app///notes/study-of-colorization</link>
<guid isPermaLink="true">https://simply-jekyll.netlify.app///notes/study-of-colorization</guid>
</item>
<item>
  <title>How does tree metrics works</title>
  <description>&lt;h1 id=&quot;comparing-mlted-rf-distance-and-treevec&quot;&gt;Comparing MLTED, RF distance, and TreeVec&lt;/h1&gt;
    &lt;h2 id=&quot;mlted&quot;&gt;MLTED&lt;/h2&gt;
    &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;img src=&quot;../assets/imgs/mlted_tree1.png&quot; alt=&quot;&quot; /&gt;&lt;/th&gt;
    &lt;th&gt;&lt;img src=&quot;../assets/imgs/mlted_tree2.png&quot; alt=&quot;&quot; /&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
    &lt;td&gt;Tree 1&lt;/td&gt;
    &lt;td&gt;Tree 2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/mlted_tree3.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/mlted_tree4.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;Tree 3&lt;/td&gt;
    &lt;td&gt;Tree 4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/mlted_tree5.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/mlted_tree6.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;Tree 5&lt;/td&gt;
    &lt;td&gt;Tree 6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
    &lt;/table&gt;
    &lt;p&gt;On comparision of tree 1 with tree3 and 4, the output from MLTED was 100% similarity and 0 edit distance with the normalized output as 1. Even though Tree(1) as only three nodes while others have many more. It is because Tree(1) is lacking information which other trees have but there is no error in the output which needs to be corrected. When the comparison is made between Tree(2) and Tree(1, 3, 4), edit distance of 14 was found in each case and similarity of 3 because only three nodes are common (a, b, c) in any pair and Tree(2) on the one hand is projecting taxa(b, c, d) as independent (parallel) while in other trees these three mutations happens simultaneously. Tree(5) deals with the condition when one tree shows different order of mutation than the other, while Tree(6) addons to Tree(5) by replacing the root with some other elements.&lt;/p&gt;
    &lt;ul&gt;
    &lt;li&gt;Tree(5)
    &lt;ul&gt;
    &lt;li&gt;With Tree(1)
    100% similarity(of 10), as already described.&lt;/li&gt;
    &lt;li&gt;Tree(2)
    Similarity of 3, as already described.&lt;/li&gt;
    &lt;li&gt;Tree(3)
    Similarity of 9, and edit distance of 2. It is because 9 nodes are in correct position out of 10 (h is not in). 1 distance is required to remove h, and other to add it as child of g.&lt;/li&gt;
    &lt;li&gt;Tree(4)
    Similarity of 4, as we have shuffled nodes.&lt;/li&gt;
    &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;Tree(6)
    &lt;ul&gt;
    &lt;li&gt;
    &lt;p&gt;With Tree(1)&lt;/p&gt;
    &lt;p&gt;Similarity of 8 and distance of 4,&lt;/p&gt;
    &lt;ul&gt;
    &lt;li&gt;1 to remove a from b node.&lt;/li&gt;
    &lt;li&gt;1 to remove g from the b node.&lt;/li&gt;
    &lt;li&gt;1 to add b as child of a.&lt;/li&gt;
    &lt;li&gt;1 to add g as child of a.&lt;/li&gt;
    &lt;/ul&gt;
    &lt;/li&gt;
    &lt;/ul&gt;
    &lt;/li&gt;
    &lt;/ul&gt;
    &lt;p&gt;The final score can be calculated in two ways, $\frac{similarity}{num_nodes}$, or $\frac{edit_distance}{2*num_nodes}$.&lt;/p&gt;
    &lt;h2 id=&quot;rf-metric&quot;&gt;RF metric,&lt;/h2&gt;
    &lt;p&gt;It is implied by sum of two terms, A+B where A represents number of partition of data implied by $T_1$ but not $T_2$, while B represents versa. RF metric ensures that we have exact ordering of taxas in tree whereas MLTED only ensured that nodes(can contain multiple taxas) are in correct order.
    It is not possible to compare the trees present in the above tables, as RF metric requires same set of leaf nodes in the tree. Therefore, table given below will help in better understanding of RF metric.&lt;/p&gt;
    &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;img src=&quot;../assets/imgs/rf_tree1.png&quot; alt=&quot;&quot; /&gt;&lt;/th&gt;
    &lt;th&gt;&lt;img src=&quot;../assets/imgs/rf_tree2.png&quot; alt=&quot;&quot; /&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
    &lt;td&gt;Tree 1&lt;/td&gt;
    &lt;td&gt;Tree 2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/rf_tree3.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;../assets/imgs/rf_tree4.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;Tree 3&lt;/td&gt;
    &lt;td&gt;Edges Labelled&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
    &lt;/table&gt;
    &lt;p&gt;In RF distance, we are required to calculate the sum of splits which are present in tree 1 but not tree 2 and vice versa. Therefore using the edge labelling (in red color). We define split of each tree (q split is not required as it would be same as that of x) as&lt;/p&gt;
    &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;Tree 1&lt;/th&gt;
    &lt;th&gt;Tree 2&lt;/th&gt;
    &lt;th&gt;Tree 3&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
    &lt;td&gt;C(x)ABD&lt;/td&gt;
    &lt;td&gt;C(x)ABD&lt;/td&gt;
    &lt;td&gt;B(x)ACD&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;D(y)ABC&lt;/td&gt;
    &lt;td&gt;B(y)ADC&lt;/td&gt;
    &lt;td&gt;C(y)ABD&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;B(z)ACD&lt;/td&gt;
    &lt;td&gt;D(z)ACB&lt;/td&gt;
    &lt;td&gt;D(z)ACB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;A(r)BCD&lt;/td&gt;
    &lt;td&gt;A(r)BCD&lt;/td&gt;
    &lt;td&gt;A(r)BCD&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;BD(p)AC&lt;/td&gt;
    &lt;td&gt;BD(p)AC&lt;/td&gt;
    &lt;td&gt;CD(p)AB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
    &lt;/table&gt;
    &lt;p&gt;The splits between Tree(1) and Tree(2) as it does not matter which branch splits it because of being unrooted. While there are two unique splits in case of Tree(3) and Tree(1) or Tree(2). Thus, RF distance would be 2 in this case. If needed normalization then it is done by dividing it with total number of splits presents in both of the tree. Therotically, we are not bounded by comparing tree which does not have same number of leaves but tools does not allow.&lt;/p&gt;
    &lt;h2 id=&quot;treevec&quot;&gt;TreeVec&lt;/h2&gt;
    &lt;p&gt;It is also a metric for unrooted tree, and is primarly to pool different taxas based on their context. Basically, if the tree has leaf nodes as ${a_1, a_2, b_1, b_2}$. It implies $a_1, a_2$ belongs to category a while $b_1, b_2$ belongs to category b. No other method can help in this case. So, this method is very trivial.&lt;/p&gt;
    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;0
    1
    2
    &lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nc&quot;&gt;Calculates&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minimum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depth&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;can&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;be&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;assigned&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;any&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;leaf&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Take&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;all&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depths&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;all&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;categories&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Compute&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Eucledian&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;between&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;all&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;categories&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;all&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trees&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
    &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
    &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;img src=&quot;../assets/imgs/treevec_tree1&quot; alt=&quot;&quot; /&gt;&lt;/th&gt;
    &lt;th&gt;&lt;img src=&quot;../assets/imgs/treevec_tree2&quot; alt=&quot;&quot; /&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
    &lt;td&gt;Tree(1)&lt;/td&gt;
    &lt;td&gt;Tree(2)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
    &lt;/table&gt;
    &lt;p&gt;In this example, there are no examples in the subcategories.Minimum depth for each pair of the nodes is presented in the table below.&lt;/p&gt;
    &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;Pair&lt;/th&gt;
    &lt;th&gt;Tree(1)&lt;/th&gt;
    &lt;th&gt;Tree(2)&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
    &lt;td&gt;$a \to b$&lt;/td&gt;
    &lt;td&gt;0&lt;/td&gt;
    &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;$a \to c$&lt;/td&gt;
    &lt;td&gt;0&lt;/td&gt;
    &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;$a \to d$&lt;/td&gt;
    &lt;td&gt;0&lt;/td&gt;
    &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;$a \to e$&lt;/td&gt;
    &lt;td&gt;0&lt;/td&gt;
    &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;$b \to c$&lt;/td&gt;
    &lt;td&gt;1&lt;/td&gt;
    &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;$b \to d$&lt;/td&gt;
    &lt;td&gt;1&lt;/td&gt;
    &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;$b \to e$&lt;/td&gt;
    &lt;td&gt;1&lt;/td&gt;
    &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;$c \to d$&lt;/td&gt;
    &lt;td&gt;2&lt;/td&gt;
    &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;$c \to e$&lt;/td&gt;
    &lt;td&gt;2&lt;/td&gt;
    &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;$d \to e$&lt;/td&gt;
    &lt;td&gt;3&lt;/td&gt;
    &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
    &lt;/table&gt;
    &lt;p&gt;Thus, final distance is calculated between these two vectors (eucleadian in this example), 4.89.&lt;/p&gt;
  </description>
  <pubDate>Mon, 17 Aug 2020 00:00:00 -0500</pubDate>
  <link>https://simply-jekyll.netlify.app///notes/tree_metrics_in_detail</link>
<guid isPermaLink="true">https://simply-jekyll.netlify.app///notes/tree_metrics_in_detail</guid>
</item>
<item>
  <title>Basics of Phylogeny</title>
  <description>&lt;h1 id=&quot;phylogeny&quot;&gt;Phylogeny&lt;/h1&gt;
    &lt;p&gt;Given a VAFs, the task is to generate ancestoral tree such that it adheres to the principles of perfect phylogeny.&lt;/p&gt;
    &lt;h2 id=&quot;terminology&quot;&gt;Terminology&lt;/h2&gt;
    &lt;ul&gt;
    &lt;li&gt;M matrix of size $(m, n)$ denotes the presence of $m^{th}$ mutation in $n^{th}$ location of the tumor.&lt;/li&gt;
    &lt;li&gt;V matrix of size $(m, n)$ represents VAFs of $m^{th}$ sample in $n^{th}$ location of the tumor.&lt;/li&gt;
    &lt;li&gt;T tree, provides the ancestoral representation of mutations based on phylogeny of M matrix.&lt;/li&gt;
    &lt;li&gt;Character, represents the language of mutation and in our case T or A denoting whether Tumor has been found at a particular site or not.&lt;/li&gt;
    &lt;/ul&gt;
    &lt;h2 id=&quot;perfect-phylogeny&quot;&gt;Perfect Phylogeny&lt;/h2&gt;
    &lt;blockquote&gt;
    &lt;p&gt;A phylogeny tree is perfect if it follows the following principle,&lt;/p&gt;
    &lt;/blockquote&gt;
    &lt;ul&gt;
    &lt;li&gt;Mathematically, there should be no conflict between the mutations at any two sites.&lt;/li&gt;
    &lt;/ul&gt;
    \[Conflict (i, j) = 
    \begin{cases}
    true, &amp;amp; \text{} M[k, j] \nleqslant M[k, i], M[k, j] \ngeqslant M[k, i], \forall k \in m.  \\
    &amp;amp;\text{} M[k, j] = M[k, i], \exists k \in m.  \\
    false, &amp;amp; otherwise
    \end{cases}\]
    &lt;p&gt;$\quad$ for example,&lt;/p&gt;
    \[M = \begin{bmatrix}
    1&amp;amp;0&amp;amp;0&amp;amp;0\\
    1&amp;amp;1&amp;amp;1&amp;amp;0\\
    0&amp;amp;0&amp;amp;0&amp;amp;1\\
    0&amp;amp;1&amp;amp;0&amp;amp;0
    \end{bmatrix}\]
    &lt;p&gt;$\quad$ Column 1 and 2 in Matrix, M are in conflict while column 3 and 4 are not.&lt;/p&gt;
    &lt;ul&gt;
    &lt;li&gt;
    &lt;p&gt;Intutively, it is because we can say that that column 3 is ancestoral clone of column 2 but we cant say the same for column 1 and 2. While with column 3 and 4, we can say these are not ancestoral clones.&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
    &lt;p&gt;Perfect Phylogeny, also ensures the invention of new character&lt;a class=&quot;citation&quot; href=&quot;#vingron2003algorithms&quot;&gt;[1]&lt;/a&gt; is a rare events and does not happen in multiple sites across the phylogeny tree.&lt;/p&gt;
    &lt;/li&gt;
    &lt;/ul&gt;
    &lt;h3 id=&quot;generation-of-evolutionary-tree-from-perfect-phylogeny&quot;&gt;Generation of Evolutionary tree from Perfect Phylogeny&lt;/h3&gt;
    &lt;p&gt;Given M, which has no conflict present in the columns, finding ancestors required as to&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;0
    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    &lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;Input : M
    function(map)
    function(M):
    sort(M) over columns.
    append($C_0$, M), where $C_0 \in \{0\}.$ 
    for $C, C&apos;$ in columns, where $C&apos; \ne C$:
    if $C&apos; \subseteq C$ then
    draw an edge in T from $C \to C&apos;$;
    for each_node in T:
    get(characters required)
    check : any row uses these characters
    if yes:
    label node as that row.
    &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    \[M = \begin{bmatrix}
    0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1\\
    0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0\\
    0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;1&amp;amp;0\\
    0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0\\
    0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\
    0&amp;amp;1&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\
    1&amp;amp;1&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0
    \end{bmatrix},
    M_{sorted} = 
    \begin{bmatrix}
    1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1\\
    1&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\
    1&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0\\
    1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0\\
    1&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\
    1&amp;amp;1&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\
    1&amp;amp;1&amp;amp;1&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0
    \end{bmatrix}\]
    &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;img src=&quot;../assets/imgs/phylogeny_m_inpt.png&quot; alt=&quot;&quot; /&gt;&lt;/th&gt;
    &lt;th&gt;&lt;img src=&quot;../assets/imgs/columns_decomposition.png&quot; alt=&quot;&quot; /&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
    &lt;td&gt;Tree with nodes representing columns&lt;/td&gt;
    &lt;td&gt;Tree with nodes representing mutation, and Yellow color nodes representing derived mutation&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
    &lt;/table&gt;
    &lt;h2 id=&quot;importance-of-vafs-in-phylogeny&quot;&gt;Importance of VAFs in phylogeny&lt;/h2&gt;
    &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;img src=&quot;../assets/imgs/phylogeny_vaf_inpt.png&quot; alt=&quot;&quot; /&gt;&lt;/th&gt;
    &lt;th&gt;&lt;img src=&quot;../assets/imgs/vaf_columns_decomposition.png&quot; alt=&quot;&quot; /&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
    &lt;td&gt;Tree with nodes representing columns&lt;/td&gt;
    &lt;td&gt;Tree with nodes representing mutation, and Yellow color nodes representing derived mutation&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
    &lt;/table&gt;
    &lt;p&gt;When we added VAFs information to the mutations, we were able to infer inner relationship between the nodes which got lost with binary representation of M matrix.&lt;/p&gt;
    &lt;h2 id=&quot;maximum-parsimony&quot;&gt;Maximum Parsimony&lt;/h2&gt;
    &lt;ul&gt;
    &lt;li&gt;In real world experiments, we are not gurranteed to get perfect phylogeny from the sequencing, and that’s where the principle of maximum parsimony plays its role.&lt;/li&gt;
    &lt;li&gt;Our aim is to generate parsimonious tree from the input data, i.e. a tree which can represent the M matrix in the best possible representation.&lt;/li&gt;
    &lt;li&gt;Algorithm (It uses distance based clustering for generation of tree, and Fitcher’s small parsimony principle for labeling of derived clones)
    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;0
    1
    2
    3
    &lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;      &lt;span class=&quot;nc&quot;&gt;Create&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;separate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cluster&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;Iteratively&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;till&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;we&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;have&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;only&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;one&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cluster&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Given&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;all&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clusters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;merge&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;two&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clusters&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;which&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;has&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minimum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
    &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;where&lt;/p&gt;
    \[distance(a, b) = \frac{distance(a) + distance(b)}{2},\]
    &lt;p&gt;and initial distance between two clones are calculated as the edit distance between two clones.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;0
    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    &lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;      Given : Tree
    At first,
    In bottom up fashion, for each location(k) of node i,$$
    Cn_i^k = \begin{cases}
    \cup(Cn_j^k) &amp;amp; if \cap(Cn_j^k) = \phi, where\ n_j = child(n_i)\\
    \cap(Cn_j^k) &amp;amp; otherwise\\
    \end{cases}
    $$
    In the top down fashion, for each location(k) of node i,$$
    Cn_i^k = \begin{cases}
    Cn_i^k = Cn_j^k &amp;amp; if Cn_j^k \in Cn_i^k, where\ n_j^k = parent(n_i^k)\\
    Cn_i^k = random(Cn_i^k, 1) &amp;amp; otherwise
    \end{cases}
    $$
    &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;/li&gt;
    &lt;/ul&gt;
    &lt;h2 id=&quot;mixphy&quot;&gt;MixPhy&lt;/h2&gt;
    &lt;ul&gt;
    &lt;li&gt;With Fletcher’s Algorithm and Agglomerative clustering, we aimed to find the best parsimonious tree from the M but it does not takes into the account key factors that clones in M might have been mixed.&lt;/li&gt;
    &lt;li&gt;That’s where the problem of Maximum parsimony comes into account. The problem states that we have to find the best steiner tree from the input M.&lt;/li&gt;
    &lt;li&gt;MixPhy solved this Np-hard problem heuristically by restructing the input as a perfect graph and coloring rows which will get split into multiple clones.&lt;/li&gt;
    &lt;li&gt;Algorithm
    &lt;ul&gt;
    &lt;li&gt;For the given M, create a graph, G in which two columns are connected if either one is contained in another.
    where, contained is defined as if all of the element are either $\leq$ or $\geq$.&lt;/li&gt;
    &lt;li&gt;As the containment is a transitive in nature,&lt;/li&gt;
    &lt;li&gt;i.e. if {0, 0, 1} is contained in {0, 1, 1} and {0, 1, 1} is contained in {1, 1, 1} then {0, 0, 1} is also contained in {1, 1, 1}&lt;/li&gt;
    &lt;li&gt;Thus the output graphs becomes perfect in nature, and the problem of finding cliques becomes polynomially complex.&lt;/li&gt;
    &lt;li&gt;If we observe the complement of G is the conflict graph in which any two columns are connected if both are conflicting in nature.&lt;/li&gt;
    &lt;li&gt;Thus coloring a clique of graph G, with the same color will lead to no two adjacent columns having the same color in the conflict graph.&lt;/li&gt;
    &lt;li&gt;and for each row in M:
    if color of all of the mutated column is same, then we do not need to split it
    otherwise it will get splitted into k different rows where k are the number of unique colors required to color that row.&lt;/li&gt;
    &lt;/ul&gt;
    &lt;/li&gt;
    &lt;/ul&gt;
  </description>
  <pubDate>Thu, 13 Aug 2020 00:00:00 -0500</pubDate>
  <link>https://simply-jekyll.netlify.app///notes/basics_of_clonal_evolution</link>
<guid isPermaLink="true">https://simply-jekyll.netlify.app///notes/basics_of_clonal_evolution</guid>
</item>
<item>
  <title>Introduction to Explainable AI</title>
  <description>&lt;h2 id=&quot;paper---1-measuring-the-quality-of-explanations-the-system-causability-scale&quot;&gt;Paper - 1, Measuring the Quality of Explanations: The System Causability Scale&lt;/h2&gt;
    &lt;ul&gt;
    &lt;li&gt;With the current advancements in Machine Learning, and AI. It is not possible to develop autonomous systems which can learn.
    &lt;ul&gt;
    &lt;li&gt;But this also leads to opaques in terms of their performance, and under what circumstances or conditions leads to change in their observation and performance.&lt;/li&gt;
    &lt;li&gt;It becomes certainly important in critical systems like Medical Imaging, or self driving car, or automatic flight systems.&lt;/li&gt;
    &lt;li&gt;It does not foster trust, acceptance and the most important &lt;strong&gt;responsibility&lt;/strong&gt;.&lt;/li&gt;
    &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;Explainable AI aims to&lt;/li&gt;
    &lt;/ul&gt;
  </description>
  <pubDate>Mon, 13 Jan 2020 00:00:00 -0600</pubDate>
  <link>https://simply-jekyll.netlify.app///notes/xAI/intro</link>
<guid isPermaLink="true">https://simply-jekyll.netlify.app///notes/xAI/intro</guid>
</item>
<item>
  <title>SOP Key points, and Drafts</title>
  <description>&lt;h2 id=&quot;final-version&quot;&gt;Final Version&lt;/h2&gt;
    &lt;p&gt;The study of intelligence focuses on three &lt;strong&gt;fundamental approaches&lt;/strong&gt; — social science, biological, and technological, with the end goal being creating intelligence.&lt;/p&gt;
    &lt;p&gt;My decision to pursue research in artificial intelligence is inspired by the following question: &lt;em&gt;Is there anything we cannot do if we successfully combine human intellect with a computer’s efficacy?&lt;/em&gt;&lt;/p&gt;
    &lt;p&gt;I have gained a breadth of knowledge in A.I. from working on &lt;em&gt;ETA prediction of buses running in Delhi&lt;/em&gt;, &lt;em&gt;Infrared to RGB image translation&lt;/em&gt;, &lt;em&gt;prediction root-cause mutation behind a tumor&lt;/em&gt;. Even though each problem has different inputs, parameters, and outputs, the same class of algorithms achieve the state of the art results. Thus, creating artificial intelligence is not limited to technologizing intelligence models seen in humans but involves venturing into uncharted territories, opening up infinite possibilities.&lt;/p&gt;
    &lt;p&gt;I wish to delve into A.I. at a much deeper level focusing on natural language understanding, computer vision, reinforcement learning, and being closely involved in advancing these areas. Hence, I want to focus on a career in research, where I know I will be continuously challenged and will have the chance to work on revolutionary technologies that help shape A.I.’s future.&lt;/p&gt;
    &lt;p&gt;In my junior year of undergraduate studies, I worked on my first project in Artificial Intelligence. The goal was to detect emotion from speech using a Deep Neural Network and Extreme Learning Machine. I used the experience gained in this project to work on the Cocktail party problem, which aims to extract the desired speech from a mixture of sounds. We developed an algorithm based on Speech Synthesis architecture, which models the source speaker’s mel spectrogram directly rather than learning the mask on the input mixture.&lt;/p&gt;
    &lt;p&gt;In my freshman year of graduate studies, I worked on the Image Colorization problem, intending to model the color distribution conditioned on grayscale input. Initially, we solved it in a discriminative manner, i.e., if we give the same image n times, the output remains the same. But as we know, Image Colorization is an ill-defined problem; for a given grayscale input, there can be more than one possible color image. To achieve that, we expanded it to work in a generative fashion using an autoregressive algorithm.&lt;/p&gt;
    &lt;p&gt;I decided to continue working on image colorization during my next semester, focusing on reducing the artifacts and improving the coloring of larger objects. To achieve this, we fed the output to a fully convolutional network, acting as a denoiser, inspired by Tacotron, a source synthesis architecture. After that, my professor suggested applying image colorization on I.R. images. In applications under low lighting, I.R. cameras come in handy, but interpreting I.R. images is not straightforward for a human, and hence translating to RGB improves its understandability. I.R. images introduced two challenges, i) it is no longer a self-supervised task and requires a parallel dataset, ii) it is computationally expensive since with grayscale images, we can learn the color information at less spatial resolution and upscale it, with minimal impact on visual quality but with I.R. images, we need to learn Luminicance too. I first tried the discriminative model, but the output was blurry even after extensive hyperparameter tuning. I observed that this is happening because of pair-wise loss, as the RGB images are more detailed than their I.R. counterparts, which introduces blurriness around different objects. To reduce the blurring, I trained a GAN based model, as it is not optimized using pair-wise loss.&lt;/p&gt;
    &lt;p&gt;I am quite excited to work in the domain of Contextual Matching or Project Melange because 1) I have explored both of the topics on my own, and 2) I had few ideas which I wanted to implement in both, but I could not because of time limitations. Eg. In contextual matching, I worked on a project where we first model explicit context between two sentences, followed by generating a sentence conditioned on an explicit context and an input sentence. I wanted to extend the generation process where the context is implicit, just like answering questions based on an unseen passage.&lt;/p&gt;
    &lt;ul&gt;
    &lt;li&gt;https://www.careereducation.columbia.edu/resources/resumes-impact-creating-strong-bullet-points&lt;/li&gt;
    &lt;li&gt;
    &lt;h2 id=&quot;httpswwwinccombill-murphy-jrgoogle-recruiters-say-these-5-resume-tips-including-x-y-z-formula-will-improve-your-odds-of-getting-hired-at-googlehtml&quot;&gt;https://www.inc.com/bill-murphy-jr/google-recruiters-say-these-5-resume-tips-including-x-y-z-formula-will-improve-your-odds-of-getting-hired-at-google.html&lt;/h2&gt;
    &lt;/li&gt;
    &lt;/ul&gt;
    &lt;h2 id=&quot;key-points&quot;&gt;Key points&lt;/h2&gt;
    &lt;ul&gt;
    &lt;li&gt;Class 9th
    &lt;ul&gt;
    &lt;li&gt;9.0 pointer, science project&lt;/li&gt;
    &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;Class 10th
    &lt;ul&gt;
    &lt;li&gt;10.0 pointer, merit&lt;/li&gt;
    &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;Class 11th
    &lt;ul&gt;
    &lt;li&gt;Downfall&lt;/li&gt;
    &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;Class 12th
    &lt;ul&gt;
    &lt;li&gt;95 in PCM, apart nothing&lt;/li&gt;
    &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;Bachelors into CS without much of knowledge except basics of HTML
    &lt;ul&gt;
    &lt;li&gt;first yr
    &lt;ul&gt;
    &lt;li&gt;build an image compression algorithm in Matlab,&lt;/li&gt;
    &lt;li&gt;developed a string search algorithm based on tries, serialization, and hashing&lt;/li&gt;
    &lt;li&gt;3d modeling of space capsule demonstrating the importance of dome at the bottom.&lt;/li&gt;
    &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;second semester
    &lt;ul&gt;
    &lt;li&gt;…&lt;/li&gt;
    &lt;/ul&gt;
    &lt;/li&gt;
    &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;Comprehensive Projects
    &lt;ul&gt;
    &lt;li&gt;IBM Quantum Challenge, participation in&lt;/li&gt;
    &lt;li&gt;Grayscale and Infrared Image Colorization&lt;/li&gt;
    &lt;li&gt;Object Detection&lt;/li&gt;
    &lt;li&gt;Speech Generation, and Source separation&lt;/li&gt;
    &lt;li&gt;ETA prediction&lt;/li&gt;
    &lt;li&gt;Phylogeny estimation&lt;/li&gt;
    &lt;li&gt;Conditional Generation of sentences&lt;/li&gt;
    &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;Undergraduation
    &lt;ul&gt;
    &lt;li&gt;My Majors include mathematics, computer science and electronics and :q&lt;/li&gt;
    &lt;li&gt;have worked majorly in optimization of algorithms and developing new tools to aid other users in one way or another.&lt;/li&gt;
    &lt;li&gt;Then during my second year internship, I worked with DRDO over machine consciousness and here is where I was introduced with Human Computer interaction somewhat. My major work lied in the understanding what machine consciousness is, it was majorily theortical based.&lt;/li&gt;
    &lt;li&gt;I also in the mean time worked in scraping and building automatic testing tools by using phantomJS.&lt;/li&gt;
    &lt;li&gt;During my 3rd year internship, I went to National Aeronautics Laborities Bengaluru, there I was selected as APJ Abdul Kalam Scholar to work with CSIR under project invoving keytrokes dynamics and its currently at brink of completion (I was able to complete it using RNNs and was working on research paper but then I found out about the CNNS and how much efficient they are, then I asked my professor about it and he was fine, so I am completing CNN implementation of it)&lt;/li&gt;
    &lt;li&gt;It was to develop an algorithm which  reduce access time of large corpus using tries and hashing, at the end we also implemented serialization to store bytestream directly and that’s why my major interest shifted to Java. After that for another 6 months, I completely focused on developing algorithms and applications over Java.&lt;/li&gt;
    &lt;li&gt;It was complemented by internship at DRDO, which helped me learning the concepts of neural networks, consciousness and whether consciousness can be derived in machines or not. This was majorly a theoretical internship with prototyping over a tank bot, but it helped me in laying my foundations of machine learning.&lt;/li&gt;
    &lt;li&gt;During my next summer I won a scholarship under APJ Abdul Kalam Fellowship and was given opportunity to work at National Aeronautics laboratories in CSIR-4Pi under Senior Principal Scientist Dr. GK Patra. I worked on a project involving time series analysis of keystrokes dynamics and natural language analysis of keystrokes to increase the accuracy of prediction.&lt;/li&gt;
    &lt;/ul&gt;
    &lt;/li&gt;
    &lt;/ul&gt;
  </description>
  <pubDate>Fri, 10 Jan 2020 00:00:00 -0600</pubDate>
  <link>https://simply-jekyll.netlify.app///thoughts/SOP</link>
<guid isPermaLink="true">https://simply-jekyll.netlify.app///thoughts/SOP</guid>
</item>
</channel>
</rss>